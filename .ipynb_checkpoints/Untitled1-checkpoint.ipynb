{
 "metadata": {
  "name": "",
  "signature": "sha256:16119388e91cf850d4ed3c8e4e6c5599ec3c946c3d0baaaa78863c0925949b37"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, sys, glob\n",
      "import datetime as dt\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "from db_models import Stream\n",
      "from distutils.dir_util import mkpath\n",
      "import multiprocessing\n",
      "from cdr_settings import cdr_settings as settings\n",
      "\n",
      "\n",
      "# stream=session.query(Stream).filter(Stream.name=='voice').first()\n",
      "\n",
      "class cdr_etl():\n",
      "    \n",
      "Session = sessionmaker(bind=settings.engine)\n",
      "session = Session()\n",
      "\n",
      "    def __init__(self,cdr_name,ref_date):\n",
      "        \n",
      "        stream=session.query(Stream).filter(Stream.name=='voice').first()\n",
      "        stream.no_threads=20\n",
      "        self.in_dir=os.path.join(settings.working_dir, 'in')\n",
      "        self.load_dir=os.path.join(os.path.join(settings.working_dir, 'load'), stream.name)\n",
      "        self.script_dir=os.path.join(settings.working_dir, 'script')\n",
      "        self.ref_date= ref_date.strftime(\"%Y%m%d\")\n",
      "        self.search_term='*'+self.ref_date+'*' #should be passed from db as cdr.search_term\n",
      "        self.session_id='34ER'\n",
      "        \n",
      "        \n",
      "    def get_cdrs(self): \n",
      "        files= glob.glob(self.in_dir+'/'+self.search_term)[:stream.files_per_session]\n",
      "        #remove loaded files\n",
      "        #files=remove_loaded(files)\n",
      "        #check if cdr.is_compressed then uncompress \n",
      "        return files\n",
      "    \n",
      "    def uncompress():\n",
      "        pass\n",
      "    \n",
      "    def mkdir_p(self, path):\n",
      "\n",
      "        try:\n",
      "            os.stat(path)\n",
      "        except:\n",
      "            os.mkdir(path)       \n",
      "\n",
      "        f = file(filename)\n",
      "\n",
      "    def remove_loaded(self,files):\n",
      "        #query db and get a list of previously loaded files as loaded_files\n",
      "        #call move_to_archive(loaded_files)\n",
      "        pass\n",
      "    \n",
      "    def move_to_archive(self):\n",
      "        #move all files to archive partitioned by date on the files names\n",
      "        pass\n",
      "    \n",
      "    def test(self):\n",
      "        print self.script_dir\n",
      "        print stream.name\n",
      "        print stream.files_per_session\n",
      "        print stream.no_threads\n",
      "         \n",
      "    def distribute(self):\n",
      "        # create the files -- this will be the array from ls\n",
      "        files=self.get_cdrs()\n",
      "        # create dir or in this case array that contain the sub dir or array that amount to the number of thread\n",
      "        cdr=[[] for i in range(stream.no_threads)]\n",
      "        # allocate spaces for the number of files to go into each thread based on the number of files coming\n",
      "        i=0\n",
      "        for file in files:\n",
      "            cdr[i].append(file)\n",
      "            i+=1\n",
      "            if i==stream.no_threads:\n",
      "                i=0\n",
      "        return cdr\n",
      "    \n",
      "    def distribute2(self):\n",
      "        \"\"\"@TODO :this method aim to distributes files in such so the the files are in the folders sequecially i.e  folder one contains \n",
      "        the first 1-10 files and the last folder contains the last set of files i.e the reminder\"\"\"\n",
      "        \n",
      "        os.chdir(self.in_dir)\n",
      "        # create the files -- this will be the array from ls\n",
      "        files=self.get_cdrs()\n",
      "        # create dir or in this case array that contain the sub dir or array that amount to the number of thread\n",
      "        cdr=[[] for i in range(stream.no_threads)]\n",
      "        # allocate spaces for the number of files to go into each thread based on the number of files coming\n",
      "        interval=stream.files_per_session/stream.no_threads\n",
      "        mod_int= stream.files_per_session%stream.no_threads\n",
      "        for i in range(self.no_threads):\n",
      "            for j in range (interval):\n",
      "                cdr[i].append([])\n",
      "\n",
      "            if i <= mod_int-1:\n",
      "                cdr[i].append([])\n",
      "                print mod_int,i \n",
      "\n",
      "        n=0\n",
      "        for i in range (self.no_threads):\n",
      "        #     print 'filse', i, len(cdr[i])\n",
      "        #     print n, n+len(cdr[i])\n",
      "            cdr[i]=files[n:n+len(cdr[i])]\n",
      "            n=n+len(cdr[i])\n",
      "\n",
      "#         for i in range(self.no_threads):\n",
      "#             print len(cdr[i])\n",
      "#             print cdr[i]\n",
      "#             process_cdr (cdr[i], i)\n",
      "            \n",
      "    def process_thread(self, files, thread_no):\n",
      "        print 'for thread',thread_no+1, 'there are ', len(files), 'files'     \n",
      "        #set the path to put all_data.txt\n",
      "        load_dir=self.load_dir+'/'+self.ref_date\n",
      "        #mkdir if it does not exit, if it does use\n",
      "        #@TODO: REPLACE THIS MKDIR -P WITH A PYTHON IMPLEMENTAION\n",
      "        os.system(\"mkdir -p {0}\".format(load_dir))\n",
      "        #!mkdir -p $load_dir\n",
      "        #set the name of the final files with thread_no and timestamp/session_number/sequence\n",
      "        data_file=load_dir+'/all_data_'+str(thread_no+1)+'_'+self.session_id+'.txt'\n",
      "        if os.path.exists(data_file):\n",
      "            os.remove(data_file)\n",
      "        \n",
      "        with open(data_file, 'w') as outfile:\n",
      "            for i in range(len(files)):\n",
      "                fname=files[i]\n",
      "                with open(fname) as infile:\n",
      "                    for line in infile:\n",
      "                        line=fname+'|'+self.ref_date+'|'+line\n",
      "                        outfile.write(line)\n",
      "        rtn='done {}'.format(thread_no+1)\n",
      "        print rtn\n",
      "        return rtn\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import  datetime as dt\n",
      "from cdr_etl import cdr_etl\n",
      "import multiprocessing as mp\n",
      "\n",
      "\n",
      "def main_generate(stream, ref_date):\n",
      "    voice_cdr=cdr_etl(stream_name,ref_date)\n",
      "    files=voice_cdr.distribute()\n",
      "    for i in range (len(files)):\n",
      "        voice_cdr.process_thread(files[i], i)  \n",
      "#     voice_cdr.test()\n",
      "\n",
      "def process_thread_parallel(files):\n",
      "    current =mp.current_process()\n",
      "    vd=files.pop(len(files)-2)\n",
      "    thread_no=files.pop(len(files)-1)\n",
      "#     vd.test()\n",
      "#     print current.name\n",
      "#     print os.getpid()\n",
      "#     print files[len(files)-1]\n",
      "    rtn=vd.process_thread(files,thread_no)\n",
      "    return rtn\n",
      "\n",
      "\n",
      "def main_generate_parallel(stream, ref_date):\n",
      "    voice_cdr=cdr_etl(stream_name,ref_date)\n",
      "    files=voice_cdr.distribute()\n",
      "    #append the class and thread no to the files for each thread\n",
      "    for i in range (len(files)):\n",
      "        files[i].append(voice_cdr)\n",
      "        files[i].append(i)\n",
      "    p = mp.Pool(5) \n",
      "    result=p.map_async(process_thread_parallel , files )\n",
      "    result.wait()\n",
      "    ppp=result.get()\n",
      "#voice_cdr.process_thread3(files)\n",
      "\n",
      "\n",
      "###############################################################################################################3\n",
      "\n",
      "ref_date=dt.datetime(2015,01,10)\n",
      "stream_name='voice'\n",
      "\n",
      "# main_generate(stream_name, ref_date)\n",
      "main_generate_parallel(stream_name, ref_date)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'stream' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-89d0ae4640e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# main_generate(stream_name, ref_date)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mmain_generate_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-2-89d0ae4640e5>\u001b[0m in \u001b[0;36mmain_generate_parallel\u001b[1;34m(stream, ref_date)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain_generate_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mvoice_cdr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcdr_etl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvoice_cdr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;31m#append the class and thread no to the files for each thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/osayamen/prog/python_etl/python_etl/script/cdr_etl.pyc\u001b[0m in \u001b[0;36mdistribute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# create the files -- this will be the array from ls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cdrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;31m# create dir or in this case array that contain the sub dir or array that amount to the number of thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mcdr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_threads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/osayamen/prog/python_etl/python_etl/script/cdr_etl.pyc\u001b[0m in \u001b[0;36mget_cdrs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_cdrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles_per_session\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m#remove loaded files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#files=remove_loaded(files)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'stream' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}